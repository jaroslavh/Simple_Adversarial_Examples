{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Examples for Vanilla Neural Networks\n",
    "\n",
    "Adversarial examples are inputs to a neural network that are designed to \"trick\" the neural network. For example, [here](https://blog.openai.com/robust-adversarial-inputs/) is a cool project that an intern at OpenAI did on adversarial examples. They managed \"convince\" an image recognition neural network that a picture of a cat was a desktop computer. Adversarial examples are incredibly important when it comes to the security of neural network models and is currently a very active field of research (for example, a [paper](https://arxiv.org/pdf/1611.02770.pdf) from Berkeley's own Dawn Song).\n",
    "\n",
    "Here is an example of an image of a panda with added noise that a neural network thinks with 99.3% confidence is a gibbon:\n",
    "\n",
    "![](https://blog.openai.com/content/images/2017/02/adversarial_img_1.png)\n",
    "\n",
    "This notebook does something similar. It takes a neural network trained to recognize handwritten digits (MNIST) and implements code to generate images that \"trick\" the neural network. For example, we'll generate images that look like a '2' but the network will think is a '6'. The digits that the network was trained on look something like this:\n",
    "\n",
    "![](http://neuralnetworksanddeeplearning.com/images/digits.png)\n",
    "\n",
    "(The neural network was implemented by Michael Nielsen for his [Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/) book. We encourage you to read it!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's import all the dependencies we'll need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import network.network as Network\n",
    "import network.mnist_loader as mnist_loader\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll unpickle the pre-trained neural network and use a helpful helper function to load up the MNIST data. The network has only one hidden layer of 30 units, 784 input units (MNIST images are $ 28 \\times 28 = 784 $ pixels large), and 10 output units. All the activations are sigmoidal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('network/trained_network.pkl', 'rb') as f:\n",
    "    u = pickle._Unpickler(f)\n",
    "    u.encoding = 'latin1'\n",
    "    net = u.load()\n",
    "    \n",
    "training_data, validation_data, test_data = mnist_loader.load_data_wrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = list(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural network is pretrained, so it should already be set up to predict characters. Run `predict(n)` to evaluate the $ n^{th} $ digit in the test set using the network. You should see that even this relatively simple network works really well (~97% accuracy). The output of the network is a one-hot vector indicating the network's predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(n):\n",
    "    # Get the data from the test set\n",
    "    x = list(test_data)[n][0]\n",
    "\n",
    "    # Print the prediction of the network\n",
    "    print('Network output: \\n' + str(np.round(net.feedforward(x), 2)) + '\\n')\n",
    "    print('Network prediction: ' + str(np.argmax(net.feedforward(x))) + '\\n')\n",
    "    print('Actual image: ')\n",
    "    \n",
    "    # Draw the image\n",
    "    plt.imshow(x.reshape((28,28)), cmap='Greys')\n",
    "\n",
    "# Replace the argument with any number between 0 and 9999\n",
    "predict(8342)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To actually generate adversarial examples we solve a minimization problem. We do this by setting a \"goal\" label called $ \\vec y_{goal} $ (for instance, if we wanted the network to think the adversarial image is an 8, then we would choose $ \\vec y_{goal} $ to be a one-hot vector with the eighth entry being 1). Now we define a cost function:\n",
    "\n",
    "$$ C = \\frac{1}{2} \\|\\vec y_{goal} - \\hat y(\\vec x)\\|^2_2 $$\n",
    "\n",
    "where $ \\| \\cdot \\|^2_2 $ is the squared Euclidean norm and $ \\hat y $ is the network's output. It is a function of $ \\vec x $, the input image to the network, so we write $ \\hat y(\\vec x) $. Our goal is to find an $ \\vec x $ such that $ C $ is minimized. Hopefully this makes sense, because if we find an image $ \\vec x $ that minimizes $ C $ then that means the output of the network when given $ \\vec x $ is close to our desired output, $ \\vec y_{goal} $. So in full mathy language, our optimization problem is:\n",
    "\n",
    "$$ \\arg \\min_{\\vec x} C(\\vec x) $$\n",
    "\n",
    "that is, find the $ \\vec x $ that minimizes the cost $ C $.\n",
    "\n",
    "To actually do this we can do gradient descent on $ C $. Start with an initially random vector $ \\vec x $ and take steps (changing $ \\vec x $) gradually in the direction opposite of the gradient $ \\nabla_x C $. To actually get these derivatives we can perform backpropagation on the network. In contrast to training a network, where we perform gradient descent on the weights and biases, when we create adversarial examples we hold the weights and biases constant (because we don't want to change the network!), and change the inputs to our network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First a couple helper functions to evaluate the non-linearity and it's derivative:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"The sigmoid function.\"\"\"\n",
    "    return 1.0/(1.0+np.exp(-z))\n",
    "                                                                                                                                                                                \n",
    "def sigmoid_prime(z):\n",
    "    \"\"\"Derivative of the sigmoid function.\"\"\"\n",
    "    return sigmoid(z)*(1-sigmoid(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, a function to gradient the derivative of the cost function, $ \\nabla_x C $ with respect to the input $ \\vec x $, with a goal label of $ \\vec y_{goal} $. (Don't worry too much about the implementation, just know it calcualtes derivatives)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_derivative(net, x, y):\n",
    "    \"\"\" Calculate derivatives wrt the inputs\"\"\"\n",
    "    nabla_b = [np.zeros(b.shape) for b in net.biases]\n",
    "    nabla_w = [np.zeros(w.shape) for w in net.weights]\n",
    "    \n",
    "    # feedforward\n",
    "    activation = x\n",
    "    activations = [x] # list to store all the activations, layer by layer\n",
    "    zs = [] # list to store all the z vectors, layer by layer\n",
    "    for b, w in zip(net.biases, net.weights):\n",
    "        z = np.dot(w, activation)+b\n",
    "        zs.append(z)\n",
    "        activation = sigmoid(z)\n",
    "        activations.append(activation)\n",
    "        \n",
    "    # backward pass\n",
    "    delta = net.cost_derivative(activations[-1], y) * \\\n",
    "        sigmoid_prime(zs[-1])\n",
    "    nabla_b[-1] = delta\n",
    "    nabla_w[-1] = np.dot(delta, activations[-2].transpose())\n",
    "\n",
    "    for l in range(2, net.num_layers):\n",
    "        z = zs[-l]\n",
    "        sp = sigmoid_prime(z)\n",
    "        delta = np.dot(net.weights[-l+1].transpose(), delta) * sp\n",
    "        nabla_b[-l] = delta\n",
    "        nabla_w[-l] = np.dot(delta, activations[-l-1].transpose())\n",
    "        \n",
    "    # Return derivatives WRT to input\n",
    "    return net.weights[0].T.dot(delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual function that generates adversarial examples and a wrapper function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adversarial(net, n, steps, eta):\n",
    "    \"\"\"\n",
    "    net : network object\n",
    "        neural network instance to use\n",
    "    n : integer\n",
    "        our goal label (just an int, the function transforms it into a one-hot vector)\n",
    "    steps : integer\n",
    "        number of steps for gradient descent\n",
    "    eta : float\n",
    "        step size for gradient descent\n",
    "    \"\"\"\n",
    "    # Set the goal output\n",
    "    goal = np.zeros((10, 1))\n",
    "    goal[n] = 1\n",
    "\n",
    "    # Create a random image to initialize gradient descent with\n",
    "    x = np.random.normal(.5, .3, (784, 1))\n",
    "\n",
    "    # Gradient descent on the input\n",
    "    for i in range(steps):\n",
    "        # Calculate the derivative\n",
    "        d = input_derivative(net,x,goal)\n",
    "        \n",
    "        # The GD update on x\n",
    "        x -= eta * d\n",
    "        \n",
    "    return x\n",
    "\n",
    "# Wrapper function\n",
    "def generate(n):\n",
    "    \"\"\"\n",
    "    n : integer\n",
    "        goal label (not a one hot vector)\n",
    "    \"\"\"\n",
    "    a = adversarial(net, n, 1000, 1)\n",
    "    x = np.round(net.feedforward(a), 2)\n",
    "    \n",
    "    print('Network Output: \\n' + str(x) + '\\n')\n",
    "    \n",
    "    print('Network Prediction: ' + str(np.argmax(x)) + '\\n')\n",
    "    \n",
    "    print('Adversarial Example: ')\n",
    "    plt.imshow(a.reshape(28,28), cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's generate some adversarial examples! Use the function provided to mess around with the neural network. (For some inputs gradient descent doesn't always converge; 0 and 5 seem to work pretty well though. I suspect convergence is very highly dependent on our choice of random initial $ \\vec x $. We'll see later in the notebook if we force the adversarial example to \"look like\" a handwritten digit, convergence is much more likely. In a sense we will be adding regularization to our generation process)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sweet! We've just managed to create an image that looks utterly meaningless to a human, but the neural network thinks is a '5' with very high certainty. We can actually take this a bit further. Let's generate an image that looks like one number, but the neural network is certain is another. To do this we will modify our cost function a bit. Instead of just optimizing the input image, $ \\vec x $, to get a desired output label, we'll also optimize the input to look like a certain image, $ \\vec x_{target} $, at the same time. Our new cost function will be\n",
    "\n",
    "$$ C = \\|\\vec y_{goal} - y_{hat}(\\vec x)\\|^2_2 + \\lambda \\|\\vec x - \\vec x_{target}\\|^2_2 $$\n",
    "\n",
    "The added term tells us the distance from our $ \\vec x $ and some $ \\vec x_{target} $ (which is the image we want our adversarial example to look like). Because we want to minimize $ C $, we also want to minimize the distance between our adversarial example and this image. The $ \\lambda $ is hyperparameter that we can tune; it determines which is more important: optimizing for the desired output or optimizing for an image that looks like $ \\vec x_{target} $.\n",
    "\n",
    "If you are familiar with ridge regularization, the above cost function might look suspiciously like the ridge regression cost function. In fact, we can view this generation method as giving our model a prior, centered on our target image.\n",
    "\n",
    "Here is a function that implements optimizing the modified cost function, called `sneaky_adversarial` (because it is very sneaky). Note that the only difference between this function and `adversarial` is an additional term on the gradient descent update for the regularization term:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sneaky_adversarial(net, n, x_target, steps, eta, lam=.05):\n",
    "    \"\"\"\n",
    "    net : network object\n",
    "        neural network instance to use\n",
    "    n : integer\n",
    "        our goal label (just an int, the function transforms it into a one-hot vector)\n",
    "    x_target : numpy vector\n",
    "        our goal image for the adversarial example\n",
    "    steps : integer\n",
    "        number of steps for gradient descent\n",
    "    eta : float\n",
    "        step size for gradient descent\n",
    "    lam : float\n",
    "        lambda, our regularization parameter. Default is .05\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set the goal output\n",
    "    goal = np.zeros((10, 1))\n",
    "    goal[n] = 1\n",
    "\n",
    "    # Create a random image to initialize gradient descent with\n",
    "    x = np.random.normal(.5, .3, (784, 1))\n",
    "\n",
    "    # Gradient descent on the input\n",
    "    for i in range(steps):\n",
    "        # Calculate the derivative\n",
    "        d = input_derivative(net,x,goal)\n",
    "        \n",
    "        # The GD update on x, with an added penalty to the cost function\n",
    "        # ONLY CHANGE IS RIGHT HERE!!!\n",
    "        x -= eta * (d + lam * (x - x_target))\n",
    "\n",
    "    return x\n",
    "\n",
    "# Wrapper function\n",
    "def sneaky_generate(n, m):\n",
    "    \"\"\"\n",
    "    n: int 0-9, the target number to match\n",
    "    m: index of example image to use (from the test set)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Find random instance of m in test set\n",
    "    idx = np.random.randint(0,8000)\n",
    "    while test_data[idx][1] != m:\n",
    "        idx += 1\n",
    "    \n",
    "    # Hardcode the parameters for the wrapper function\n",
    "    a = sneaky_adversarial(net, n, test_data[idx][0], 100, 1)\n",
    "    x = np.round(net.feedforward(a), 2)\n",
    "    \n",
    "    print('\\nWhat we want our adversarial example to look like: ')\n",
    "    plt.imshow(test_data[idx][0].reshape((28,28)), cmap='Greys')\n",
    "    plt.show()\n",
    "    \n",
    "    print('\\n')\n",
    "    \n",
    "    print('Adversarial Example: ')\n",
    "    \n",
    "    plt.imshow(a.reshape(28,28), cmap='Greys')\n",
    "    plt.show()\n",
    "    \n",
    "    print('Network Prediction: ' + str(np.argmax(x)) + '\\n')\n",
    "    \n",
    "    print('Network Output: \\n' + str(x) + '\\n')\n",
    "    \n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play around with this function to make \"sneaky\" adversarial examples! (Again, some numbers converge better than others... try 0, 2, 3, 5, 6, or 8 as a target label. 1, 4, 7, and 9 still don't work as well... no idea why... We get more numbers that converge because we've added regularization term to our cost function. Perhaps changing $ \\lambda $ will get more to converge?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sneaky_generate(target label, target digit)\n",
    "adv_ex = sneaky_generate(8, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So how could we protect against these adversarial attacks? One very simple way would be to use binary thresholding. Set a pixel as completely black or completely white depending on a threshold. This should remove the \"noise\" that's always present in the adversarial images. Let's see if it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_thresholding(n, m):\n",
    "    \"\"\"\n",
    "    n: int 0-9, the target number to match\n",
    "    m: index of example image to use (from the test set)\n",
    "    \"\"\"\n",
    "    \n",
    "    x = sneaky_generate(n, m)\n",
    "\n",
    "    x = (x > .5).astype(float)\n",
    "    \n",
    "    print(\"With binary thresholding: \")\n",
    "    \n",
    "    plt.imshow(x.reshape(28,28), cmap=\"Greys\")\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Prediction with binary thresholding: \" + str(np.argmax(np.round(net.feedforward(x)))) + '\\n')\n",
    "    \n",
    "    print(\"Network output: \")\n",
    "    print(np.round(net.feedforward(x), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary_thresholding(target digit, actual digit)\n",
    "binary_thresholding(0, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like it works pretty well! However, note that most adversarial attacks, especially on convolutional neural networks trained on massive full color image sets such as imagenet, can't be defended against by a simple binary threshold.\n",
    "\n",
    "We could try one more thing that might be a bit more universal to protect our neural network against adversarial attacks. If we had access to the adversarial attack method (which we do in this case, because we're the ones implementing the attack) we could create a ton of adversarial examples, mix that up with our training dataset with the correct labels, and then retrain a network on this augmented dataset. The retrained network should learn to ignore the adversarial attacks. Here we implement a function to do just that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(n, data, steps):\n",
    "    \"\"\"\n",
    "    n : integer\n",
    "        number of adversarial examples to generate\n",
    "    data : list of tuples\n",
    "        data set to generate adversarial examples using\n",
    "    \"\"\"\n",
    "    # Our augmented training set:\n",
    "    data = list(data)\n",
    "    augmented = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        # Progress \"bar\"\n",
    "        if i % 500 == 0:\n",
    "            print(\"Generated digits: \" + str(i))\n",
    "            \n",
    "        # Randomly choose a digit that the example will look like\n",
    "        rnd_actual_digit = np.random.randint(10)\n",
    "        \n",
    "        # Find random instance of rnd_actual_digit in the training set\n",
    "        rnd_actual_idx = np.random.randint(len(data))\n",
    "        while np.argmax(data[rnd_actual_idx][1]) != rnd_actual_digit:\n",
    "            rnd_actual_idx = np.random.randint(len(data))\n",
    "        x_target = data[rnd_actual_idx][0]\n",
    "        \n",
    "        # Choose value for adversarial attack\n",
    "        rnd_fake_digit = np.random.randint(10)\n",
    "        \n",
    "        # Generate adversarial example\n",
    "        x_adversarial = sneaky_adversarial(net, rnd_fake_digit, x_target, steps, 1)\n",
    "        \n",
    "        # Add new data\n",
    "        y_actual = data[rnd_actual_idx][1]\n",
    "        \n",
    "        augmented.append((x_adversarial, y_actual))\n",
    "        \n",
    "    return augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will take quite a while (~3 min for 10000, ~15 for 50000)\n",
    "# Try 10000 examples first if you don't want to wait\n",
    "augmented = augment_data(10000, training_data, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's check to make sure our augmented dataset actually makes sense. Here we have a function that checks the $ i^{th} $ example in our augmented set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_augmented(i, augmented):\n",
    "    # Show image\n",
    "    print('Image: \\n')\n",
    "    plt.imshow(augmented[i][0].reshape(28,28), cmap='Greys')\n",
    "    plt.show()\n",
    "    \n",
    "    # Show original network prediction\n",
    "    print('Original network prediction: \\n')\n",
    "    print(np.round(net.feedforward(augmented[i][0]), 2))\n",
    "    \n",
    "    # Show label\n",
    "    print('\\nLabel: \\n')\n",
    "    print(augmented[i][1])\n",
    "\n",
    "# check i^th adversarial image\n",
    "check_augmented(2449, augmented)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create a new neural network and train it on our augmented dataset and the original training set, using the original test set to validate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new network\n",
    "net2 = Network.Network([784, 30, 10])\n",
    "\n",
    "# Train on augmented + original training set\n",
    "net2.SGD(list(augmented) + list(training_data), 30, 10, 3.0, test_data=test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a network trained on 50000 adversarial examples in addition to 50000 original training set examples we get about 95% accuracy (it takes quite a long time as well). We can make a test set of adversarial examples by using the following function call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For some reason the training data has the format: list of tuples\n",
    "# tuple[0] is np array of image\n",
    "# tuple[1] is one hot np array of label\n",
    "# test data is also list of tuples\n",
    "# tuple[0] is np array of image\n",
    "# tuple[1] is integer of label\n",
    "# Just fixing this:\n",
    "normal_test_data = []\n",
    "\n",
    "for i in range(len(test_data)):\n",
    "    ground_truth = test_data[i][1]\n",
    "    one_hot = np.zeros(10)\n",
    "    one_hot[ground_truth] = 1\n",
    "    one_hot = np.expand_dims(one_hot, axis=1)\n",
    "    normal_test_data.append((test_data[i][0], one_hot))\n",
    "    \n",
    "\n",
    "# Using normal_test_data because of weird way data is packaged\n",
    "adversarial_test_set = augment_data(1000, normal_test_data, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's checkout the accuracy of our newly trained network on adversarial examples from the new adversarial test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(net, test_data):\n",
    "    \"\"\"\n",
    "    net : network object\n",
    "    test_data: list\n",
    "        list of 2-tuples of two arrays, one image and one label (one-hot)\n",
    "    \"\"\"\n",
    "    tot = float(len(test_data))\n",
    "    correct = 0\n",
    "    for i in range(len(test_data)):\n",
    "        correct += int(np.argmax(net.feedforward(test_data[i][0])) == np.argmax(test_data[i][1]))\n",
    "    \n",
    "    return correct / tot\n",
    "\n",
    "print('Accuracy: ' + str(accuracy(net2, adversarial_test_set)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get an accuracy of about 95% on adversarial examples, which is much better than the 0% we were getting with the original network! Oddly enough, increasing the steps when generating the `adversarial_test_set` doesn't reduce the accuracy, but reducing it enough does. This is probably because at the step size we're using the adversarial example has already converged. When we use fewer steps, the adversarial examples are only partly converged (and probably don't look that great). \n",
    "\n",
    "And finally, a function that compares the original network to the new network on adversarial examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_test(net, net2, test_data, n):\n",
    "    print('Original network prediction: ' + str(np.argmax(np.round(net.feedforward(test_data[n][0])))) + '\\n')\n",
    "    print('New network prediction: ' + str(np.argmax(np.round(net2.feedforward(test_data[n][0])))) + '\\n')\n",
    "    print('Image: \\n')\n",
    "    plt.imshow(test_data[n][0].reshape(28,28), cmap='Greys')\n",
    "\n",
    "sample_test(net, net2, adversarial_test_set, 238)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
